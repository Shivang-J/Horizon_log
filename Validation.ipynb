{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74921736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shiva\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Global Constants\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import urllib.parse\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os # For checking file paths\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# --- Configuration for Inference ---\n",
    "# Path where your DistilRoBERTa model and tokenizer are saved locally\n",
    "TRANSFORMER_LOCAL_PATH = r\"D:\\Internship ka kaam\\data.csv\\poroject\\Horizon_log\\saved_distilroberta_inference\"\n",
    "# Path where your trained MLP weights are saved\n",
    "MLP_MODEL_PATH = r\"D:\\Internship ka kaam\\data.csv\\poroject\\Horizon_log\\best_pytorch_mlp_model.pth\"\n",
    "# Path to your saved StandardScaler for 'length'\n",
    "LENGTH_SCALER_PATH = r\"D:\\Internship ka kaam\\data.csv\\poroject\\Horizon_log\\length_scaler2.pkl\"\n",
    "# Path to your saved OneHotEncoder for 'Method'\n",
    "METHOD_ENCODER_PATH = r\"D:\\Internship ka kaam\\data.csv\\poroject\\Horizon_log\\method_encoder.pkl\"\n",
    "\n",
    "# Transformer parameters (must match training)\n",
    "MAX_LENGTH = 256 # Or whatever max_length you found optimal during training\n",
    "BATCH_SIZE_INFERENCE = 64 # Can be larger than training batch_size if only doing forward pass\n",
    "\n",
    "# MLP Model Architecture parameters (must match training)\n",
    "INPUT_SIZE_MLP = 1540 # Total features: 1 (length) + 2 (one-hot method) + 768 (content CLS) + 768 (URL CLS)\n",
    "HIDDEN_SIZES_MLP = (512, 256, 128)\n",
    "OUTPUT_SIZE_MLP = 1 # Binary classification\n",
    "DROPOUT_RATE_MLP = 0.2 # Dropout is disabled in eval mode, but define for model consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc579f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference will run on: cuda\n",
      "Loading DistilRoBERTa tokenizer from D:\\Internship ka kaam\\data.csv\\poroject\\Horizon_log\\saved_distilroberta_inference...\n",
      "Loading DistilRoBERTa model from D:\\Internship ka kaam\\data.csv\\poroject\\Horizon_log\\saved_distilroberta_inference...\n",
      "DistilRoBERTa loaded successfully.\n",
      "Loading StandardScaler from D:\\Internship ka kaam\\data.csv\\poroject\\Horizon_log\\length_scaler2.pkl...\n",
      "Loading OneHotEncoder from D:\\Internship ka kaam\\data.csv\\poroject\\Horizon_log\\method_encoder.pkl...\n",
      "Preprocessing encoders/scalers loaded successfully.\n",
      "Loading PyTorch MLP model from D:\\Internship ka kaam\\data.csv\\poroject\\Horizon_log\\best_pytorch_mlp_model.pth...\n",
      "PyTorch MLP model loaded successfully.\n",
      "\n",
      "All models and preprocessing tools are ready for inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_15488\\2693360193.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mlp_model.load_state_dict(torch.load(MLP_MODEL_PATH, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Pre-trained Models and Encoders\n",
    "\n",
    "# Determine device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Inference will run on: {device}\")\n",
    "\n",
    "# --- Load DistilRoBERTa Components ---\n",
    "try:\n",
    "    print(f\"Loading DistilRoBERTa tokenizer from {TRANSFORMER_LOCAL_PATH}...\")\n",
    "    global_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_LOCAL_PATH)\n",
    "    print(f\"Loading DistilRoBERTa model from {TRANSFORMER_LOCAL_PATH}...\")\n",
    "    global_model = AutoModel.from_pretrained(TRANSFORMER_LOCAL_PATH)\n",
    "    global_model.eval() # Set to evaluation mode\n",
    "    global_model.to(device)\n",
    "    print(\"DistilRoBERTa loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading DistilRoBERTa components from local path: {e}\")\n",
    "    print(\"Attempting to load from Hugging Face Hub (requires internet)...\")\n",
    "    try:\n",
    "        global_tokenizer = AutoTokenizer.from_pretrained('distilroberta-base')\n",
    "        global_model = AutoModel.from_pretrained('distilroberta-base')\n",
    "        global_model.eval()\n",
    "        global_model.to(device)\n",
    "        print(\"DistilRoBERTa loaded successfully from Hugging Face Hub.\")\n",
    "    except Exception as e_hub:\n",
    "        print(f\"FATAL ERROR: Could not load DistilRoBERTa from local path or Hugging Face Hub: {e_hub}\")\n",
    "        exit() # Stop script if model can't be loaded\n",
    "\n",
    "# --- Load Preprocessing Encoders/Scalers ---\n",
    "try:\n",
    "    print(f\"Loading StandardScaler from {LENGTH_SCALER_PATH}...\")\n",
    "    scaler_for_length = joblib.load(LENGTH_SCALER_PATH)\n",
    "    print(f\"Loading OneHotEncoder from {METHOD_ENCODER_PATH}...\")\n",
    "    method_encoder = joblib.load(METHOD_ENCODER_PATH)\n",
    "    print(\"Preprocessing encoders/scalers loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"FATAL ERROR: Required preprocessing file not found: {e}\")\n",
    "    print(\"Please ensure 'length_scaler.pkl' and 'method_encoder.pkl' are in the correct directory.\")\n",
    "    exit() # Stop script if preprocessing tools are missing\n",
    "except Exception as e:\n",
    "    print(f\"FATAL ERROR: Error loading preprocessing tools: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Load PyTorch MLP Model ---\n",
    "# 1. Re-define the SimpleMLP class (must be the exact same as during training)\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, dropout_rate=0.2):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_size, hidden_sizes[0]))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout(dropout_rate)) # Dropout layer\n",
    "        for i in range(len(hidden_sizes) - 1):\n",
    "            layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate)) # Dropout layer\n",
    "        layers.append(nn.Linear(hidden_sizes[-1], output_size))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# 2. Instantiate the model and load its state_dict\n",
    "try:\n",
    "    print(f\"Loading PyTorch MLP model from {MLP_MODEL_PATH}...\")\n",
    "    mlp_model = SimpleMLP(INPUT_SIZE_MLP, HIDDEN_SIZES_MLP, OUTPUT_SIZE_MLP, DROPOUT_RATE_MLP).to(device)\n",
    "    mlp_model.load_state_dict(torch.load(MLP_MODEL_PATH, map_location=device))\n",
    "    mlp_model.eval() # Set to evaluation mode (crucial for inference: disables dropout, uses moving averages for BatchNorm if present)\n",
    "    print(\"PyTorch MLP model loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"FATAL ERROR: MLP model file not found: {e}\")\n",
    "    print(\"Please ensure 'best_pytorch_mlp_model.pth' is in the correct directory.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"FATAL ERROR: Error loading PyTorch MLP model: {e}\")\n",
    "    exit()\n",
    "\n",
    "print(\"\\nAll models and preprocessing tools are ready for inference.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4a7e73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Preprocessing Function for New Inference Data\n",
    "\n",
    "# Helper function to get CLS embedding (from previous training code)\n",
    "def get_cls_embedding(text: str, tokenizer, model, device, max_length: int):\n",
    "    \"\"\"\n",
    "    Helper function to get [CLS] embedding for a given text for inference.\n",
    "    Handles empty strings by returning a zero vector of the correct dimension.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        # Return a zero vector, ensuring it's on the correct device initially\n",
    "        return torch.zeros(model.config.hidden_size).to(device).cpu().numpy()\n",
    "\n",
    "    encoded_input = tokenizer(\n",
    "        text,\n",
    "        return_tensors='pt',\n",
    "        truncation=True,\n",
    "        padding='max_length', # Use max_length padding for consistent input shape\n",
    "        max_length=max_length\n",
    "    )\n",
    "    encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "        cls_embedding = model_output.last_hidden_state[0, 0, :]\n",
    "\n",
    "    return cls_embedding.cpu().numpy()\n",
    "\n",
    "\n",
    "def preprocess_inference_data(df: pd.DataFrame, batch_size: int, max_length: int):\n",
    "    \"\"\"\n",
    "    Preprocesses new inference data in a DataFrame, consistent with training.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with 'Method', 'URL', 'length', 'content' columns.\n",
    "        batch_size (int): Batch size for Transformer embedding generation.\n",
    "        max_length (int): Max sequence length for Transformer.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Preprocessed DataFrame ready for MLP prediction.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Starting Data Preprocessing for Inference ---\")\n",
    "\n",
    "    print(f\"Input DataFrame columns: {df.columns.tolist()}\")\n",
    "    if 'length' not in df.columns:\n",
    "        print(\"CRITICAL WARNING: 'length' column is NOT found in the input DataFrame.\")\n",
    "        print(\"Please ensure your input CSV has a column named 'length' (case-sensitive).\")\n",
    "        # You might want to raise an error or handle this more robustly\n",
    "        raise ValueError(\"Missing 'length' column in input DataFrame.\")\n",
    "\n",
    "    # --- 1. Prepare Text Data for Batch Processing ---\n",
    "    print(\"Preparing text data for batch processing...\")\n",
    "    # Fill NaN values with empty string and convert to list of strings\n",
    "    content_texts = df['content'].fillna('').astype(str).tolist()\n",
    "    # URL-decode all URLs here\n",
    "    url_texts = [urllib.parse.unquote(str(url)) for url in df['URL'].fillna('')]\n",
    "\n",
    "    all_content_cls_embeddings = []\n",
    "    all_url_cls_embeddings = []\n",
    "\n",
    "    # --- 2. Generate CLS Embeddings in Batches ---\n",
    "    print(f\"Generating [CLS] embeddings in batches (batch_size={batch_size}, max_length={max_length})...\")\n",
    "    num_samples = len(df)\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_content = content_texts[i:i + batch_size]\n",
    "        batch_urls = url_texts[i:i + batch_size]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Process Content Batch\n",
    "            encoded_content_batch = global_tokenizer(\n",
    "                batch_content, return_tensors='pt', truncation=True,\n",
    "                padding='longest', max_length=max_length\n",
    "            ).to(device)\n",
    "            content_output = global_model(**encoded_content_batch)\n",
    "            batch_content_cls_embeds = content_output.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "            all_content_cls_embeddings.extend(batch_content_cls_embeds)\n",
    "            del content_output, encoded_content_batch\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            # Process URL Batch\n",
    "            encoded_url_batch = global_tokenizer(\n",
    "                batch_urls, return_tensors='pt', truncation=True,\n",
    "                padding='longest', max_length=max_length\n",
    "            ).to(device)\n",
    "            url_output = global_model(**encoded_url_batch)\n",
    "            batch_url_cls_embeds = url_output.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "            all_url_cls_embeddings.extend(batch_url_cls_embeds)\n",
    "            del url_output, encoded_url_batch\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        if (i // batch_size + 1) % 10 == 0 or (i + batch_size) >= num_samples:\n",
    "            print(f\"Processed {min(i + batch_size, num_samples)}/{num_samples} samples...\")\n",
    "\n",
    "    print(\"Embedding generation complete.\")\n",
    "\n",
    "    content_embed_df = pd.DataFrame(all_content_cls_embeddings, index=df.index).add_prefix('content_embed_')\n",
    "    url_embed_df = pd.DataFrame(all_url_cls_embeddings, index=df.index).add_prefix('url_embed_')\n",
    "\n",
    "    # --- 3. One-Hot Encode 'Method' Column ---\n",
    "    print(\"One-hot encoding 'Method' column...\")\n",
    "    # Use the LOADED method_encoder (IMPORTANT: DO NOT .fit_transform() here, only .transform())\n",
    "    method_encoded = method_encoder.transform(df[['Method']])\n",
    "    method_encoded_df = pd.DataFrame(\n",
    "        method_encoded,\n",
    "        columns=method_encoder.get_feature_names_out(['Method']),\n",
    "        index=df.index\n",
    "    )\n",
    "    print(\"One-hot encoding complete.\")\n",
    "\n",
    "    # --- 4. Scale 'length' Column ---\n",
    "    print(\"Scaling 'length' column...\")\n",
    "    # Use the LOADED scaler_for_length (IMPORTANT: DO NOT .fit_transform() here, only .transform())\n",
    "    df_temp = df.copy() # Work on a copy to avoid modifying original df\n",
    "    df_temp['length'] = scaler_for_length.transform(df_temp[['length']])\n",
    "    print(\"Length scaling complete.\")\n",
    "\n",
    "    print(f\"df_temp columns BEFORE scaling: {df_temp.columns.tolist()}\")\n",
    "    if 'length' in df_temp.columns:\n",
    "        df_temp['length'] = scaler_for_length.transform(df_temp[['length']])\n",
    "        print(f\"First 5 scaled lengths: {df_temp['length'].head().tolist()}\")\n",
    "    else:\n",
    "        print(\"CRITICAL WARNING: 'length' column is MISSING in df_temp before scaling.\")\n",
    "\n",
    "    # --- 5. Combine All Features into Final DataFrame ---\n",
    "    print(\"Combining all features...\")\n",
    "    # Ensure columns are in the same order as trained data\n",
    "    # Create an empty DataFrame to build features consistently\n",
    "    preprocessed_X = pd.concat([\n",
    "        df_temp[['length']], # Scaled length\n",
    "        method_encoded_df,   # One-hot encoded methods\n",
    "        content_embed_df,    # Content embeddings\n",
    "        url_embed_df         # URL embeddings\n",
    "    ], axis=1)\n",
    "\n",
    "    # Ensure column order matches training data's X.columns if specific order is critical\n",
    "    # If the combined data forms columns that consistently match the training X.columns order, this is fine.\n",
    "    # Otherwise, you would need to store the exact X.columns from training and reindex preprocessed_X\n",
    "    # For now, assuming consistent column generation.\n",
    "    print(f\"Final preprocessed_X columns: {preprocessed_X.columns.tolist()}\")\n",
    "    print(f\"Final preprocessed_X shape: {preprocessed_X.shape}\")\n",
    "\n",
    "    print(\"Feature combination complete.\")\n",
    "    print(f\"Preprocessed features shape: {preprocessed_X.shape}\")\n",
    "    print (preprocessed_X.head())\n",
    "    return preprocessed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71511efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Prediction Function\n",
    "\n",
    "def predict_network_payload(input_csv_path: str):\n",
    "    \"\"\"\n",
    "    Receives a CSV file, preprocesses it, and predicts if payloads are benign or malicious.\n",
    "\n",
    "    Args:\n",
    "        input_csv_path (str): Path to the input CSV file with\n",
    "                              'Method', 'URL', 'length', 'content' columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Original DataFrame with an added 'Predicted_Label' column (0 or 1).\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting Prediction for: {input_csv_path} ---\")\n",
    "    \n",
    "    # 1. Load the new data\n",
    "    try:\n",
    "        new_data_df = pd.read_csv(input_csv_path)\n",
    "        print(f\"Loaded new data. Shape: {new_data_df.shape}\")\n",
    "        # Make a copy to work with, keeping original index\n",
    "        original_df_for_output = new_data_df.copy()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input CSV file not found at {input_csv_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading input CSV: {e}\")\n",
    "        return None\n",
    "\n",
    "    # 2. Preprocess the data\n",
    "    # Pass the inference batch size and max length\n",
    "    processed_features_for_pred = preprocess_inference_data(\n",
    "        new_data_df, BATCH_SIZE_INFERENCE, MAX_LENGTH\n",
    "    )\n",
    "    \n",
    "    # Convert preprocessed features to PyTorch tensor and move to device\n",
    "    X_tensor_for_pred = torch.tensor(processed_features_for_pred.values, dtype=torch.float32).to(device)\n",
    "\n",
    "    # 3. Make predictions\n",
    "    print(\"Making predictions with the MLP model...\")\n",
    "    mlp_model.eval() # Ensure model is in evaluation mode\n",
    "    with torch.no_grad():\n",
    "        raw_outputs = mlp_model(X_tensor_for_pred) # Get probabilities\n",
    "        predictions_proba = raw_outputs.cpu().numpy().flatten() # Move to CPU and flatten\n",
    "        # Apply threshold (0.5 for binary classification) to get binary labels\n",
    "        predicted_labels = (predictions_proba > 0.5).astype(int)\n",
    "    print(\"Predictions complete.\")\n",
    "\n",
    "    # 4. Add predictions to the original DataFrame and return\n",
    "    original_df_for_output['Predicted_Probability'] = predictions_proba\n",
    "    original_df_for_output['Predicted_Label'] = predicted_labels\n",
    "    \n",
    "    print(\"\\n--- Prediction Process Finished ---\")\n",
    "    print(\"Prediction counts:\")\n",
    "    print(original_df_for_output['Predicted_Label'].value_counts())\n",
    "    \n",
    "    return original_df_for_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a554fde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Prediction for: D:\\Internship ka kaam\\data.csv\\poroject\\Horizon_log\\abc.csv ---\n",
      "Loaded new data. Shape: (916, 4)\n",
      "\n",
      "--- Starting Data Preprocessing for Inference ---\n",
      "Input DataFrame columns: ['Method', 'length', 'content', 'URL']\n",
      "Preparing text data for batch processing...\n",
      "Generating [CLS] embeddings in batches (batch_size=64, max_length=256)...\n",
      "Processed 640/916 samples...\n",
      "Processed 916/916 samples...\n",
      "Embedding generation complete.\n",
      "One-hot encoding 'Method' column...\n",
      "One-hot encoding complete.\n",
      "Scaling 'length' column...\n",
      "Length scaling complete.\n",
      "df_temp columns BEFORE scaling: ['Method', 'length', 'content', 'URL']\n",
      "First 5 scaled lengths: [-0.42809160376909583, -0.42809160376909583, -0.42809160376909583, -0.42809160376909583, -0.42809160376909583]\n",
      "Combining all features...\n",
      "Final preprocessed_X columns: ['length', 'Method_GET', 'Method_POST', 'Method_PUT', 'content_embed_0', 'content_embed_1', 'content_embed_2', 'content_embed_3', 'content_embed_4', 'content_embed_5', 'content_embed_6', 'content_embed_7', 'content_embed_8', 'content_embed_9', 'content_embed_10', 'content_embed_11', 'content_embed_12', 'content_embed_13', 'content_embed_14', 'content_embed_15', 'content_embed_16', 'content_embed_17', 'content_embed_18', 'content_embed_19', 'content_embed_20', 'content_embed_21', 'content_embed_22', 'content_embed_23', 'content_embed_24', 'content_embed_25', 'content_embed_26', 'content_embed_27', 'content_embed_28', 'content_embed_29', 'content_embed_30', 'content_embed_31', 'content_embed_32', 'content_embed_33', 'content_embed_34', 'content_embed_35', 'content_embed_36', 'content_embed_37', 'content_embed_38', 'content_embed_39', 'content_embed_40', 'content_embed_41', 'content_embed_42', 'content_embed_43', 'content_embed_44', 'content_embed_45', 'content_embed_46', 'content_embed_47', 'content_embed_48', 'content_embed_49', 'content_embed_50', 'content_embed_51', 'content_embed_52', 'content_embed_53', 'content_embed_54', 'content_embed_55', 'content_embed_56', 'content_embed_57', 'content_embed_58', 'content_embed_59', 'content_embed_60', 'content_embed_61', 'content_embed_62', 'content_embed_63', 'content_embed_64', 'content_embed_65', 'content_embed_66', 'content_embed_67', 'content_embed_68', 'content_embed_69', 'content_embed_70', 'content_embed_71', 'content_embed_72', 'content_embed_73', 'content_embed_74', 'content_embed_75', 'content_embed_76', 'content_embed_77', 'content_embed_78', 'content_embed_79', 'content_embed_80', 'content_embed_81', 'content_embed_82', 'content_embed_83', 'content_embed_84', 'content_embed_85', 'content_embed_86', 'content_embed_87', 'content_embed_88', 'content_embed_89', 'content_embed_90', 'content_embed_91', 'content_embed_92', 'content_embed_93', 'content_embed_94', 'content_embed_95', 'content_embed_96', 'content_embed_97', 'content_embed_98', 'content_embed_99', 'content_embed_100', 'content_embed_101', 'content_embed_102', 'content_embed_103', 'content_embed_104', 'content_embed_105', 'content_embed_106', 'content_embed_107', 'content_embed_108', 'content_embed_109', 'content_embed_110', 'content_embed_111', 'content_embed_112', 'content_embed_113', 'content_embed_114', 'content_embed_115', 'content_embed_116', 'content_embed_117', 'content_embed_118', 'content_embed_119', 'content_embed_120', 'content_embed_121', 'content_embed_122', 'content_embed_123', 'content_embed_124', 'content_embed_125', 'content_embed_126', 'content_embed_127', 'content_embed_128', 'content_embed_129', 'content_embed_130', 'content_embed_131', 'content_embed_132', 'content_embed_133', 'content_embed_134', 'content_embed_135', 'content_embed_136', 'content_embed_137', 'content_embed_138', 'content_embed_139', 'content_embed_140', 'content_embed_141', 'content_embed_142', 'content_embed_143', 'content_embed_144', 'content_embed_145', 'content_embed_146', 'content_embed_147', 'content_embed_148', 'content_embed_149', 'content_embed_150', 'content_embed_151', 'content_embed_152', 'content_embed_153', 'content_embed_154', 'content_embed_155', 'content_embed_156', 'content_embed_157', 'content_embed_158', 'content_embed_159', 'content_embed_160', 'content_embed_161', 'content_embed_162', 'content_embed_163', 'content_embed_164', 'content_embed_165', 'content_embed_166', 'content_embed_167', 'content_embed_168', 'content_embed_169', 'content_embed_170', 'content_embed_171', 'content_embed_172', 'content_embed_173', 'content_embed_174', 'content_embed_175', 'content_embed_176', 'content_embed_177', 'content_embed_178', 'content_embed_179', 'content_embed_180', 'content_embed_181', 'content_embed_182', 'content_embed_183', 'content_embed_184', 'content_embed_185', 'content_embed_186', 'content_embed_187', 'content_embed_188', 'content_embed_189', 'content_embed_190', 'content_embed_191', 'content_embed_192', 'content_embed_193', 'content_embed_194', 'content_embed_195', 'content_embed_196', 'content_embed_197', 'content_embed_198', 'content_embed_199', 'content_embed_200', 'content_embed_201', 'content_embed_202', 'content_embed_203', 'content_embed_204', 'content_embed_205', 'content_embed_206', 'content_embed_207', 'content_embed_208', 'content_embed_209', 'content_embed_210', 'content_embed_211', 'content_embed_212', 'content_embed_213', 'content_embed_214', 'content_embed_215', 'content_embed_216', 'content_embed_217', 'content_embed_218', 'content_embed_219', 'content_embed_220', 'content_embed_221', 'content_embed_222', 'content_embed_223', 'content_embed_224', 'content_embed_225', 'content_embed_226', 'content_embed_227', 'content_embed_228', 'content_embed_229', 'content_embed_230', 'content_embed_231', 'content_embed_232', 'content_embed_233', 'content_embed_234', 'content_embed_235', 'content_embed_236', 'content_embed_237', 'content_embed_238', 'content_embed_239', 'content_embed_240', 'content_embed_241', 'content_embed_242', 'content_embed_243', 'content_embed_244', 'content_embed_245', 'content_embed_246', 'content_embed_247', 'content_embed_248', 'content_embed_249', 'content_embed_250', 'content_embed_251', 'content_embed_252', 'content_embed_253', 'content_embed_254', 'content_embed_255', 'content_embed_256', 'content_embed_257', 'content_embed_258', 'content_embed_259', 'content_embed_260', 'content_embed_261', 'content_embed_262', 'content_embed_263', 'content_embed_264', 'content_embed_265', 'content_embed_266', 'content_embed_267', 'content_embed_268', 'content_embed_269', 'content_embed_270', 'content_embed_271', 'content_embed_272', 'content_embed_273', 'content_embed_274', 'content_embed_275', 'content_embed_276', 'content_embed_277', 'content_embed_278', 'content_embed_279', 'content_embed_280', 'content_embed_281', 'content_embed_282', 'content_embed_283', 'content_embed_284', 'content_embed_285', 'content_embed_286', 'content_embed_287', 'content_embed_288', 'content_embed_289', 'content_embed_290', 'content_embed_291', 'content_embed_292', 'content_embed_293', 'content_embed_294', 'content_embed_295', 'content_embed_296', 'content_embed_297', 'content_embed_298', 'content_embed_299', 'content_embed_300', 'content_embed_301', 'content_embed_302', 'content_embed_303', 'content_embed_304', 'content_embed_305', 'content_embed_306', 'content_embed_307', 'content_embed_308', 'content_embed_309', 'content_embed_310', 'content_embed_311', 'content_embed_312', 'content_embed_313', 'content_embed_314', 'content_embed_315', 'content_embed_316', 'content_embed_317', 'content_embed_318', 'content_embed_319', 'content_embed_320', 'content_embed_321', 'content_embed_322', 'content_embed_323', 'content_embed_324', 'content_embed_325', 'content_embed_326', 'content_embed_327', 'content_embed_328', 'content_embed_329', 'content_embed_330', 'content_embed_331', 'content_embed_332', 'content_embed_333', 'content_embed_334', 'content_embed_335', 'content_embed_336', 'content_embed_337', 'content_embed_338', 'content_embed_339', 'content_embed_340', 'content_embed_341', 'content_embed_342', 'content_embed_343', 'content_embed_344', 'content_embed_345', 'content_embed_346', 'content_embed_347', 'content_embed_348', 'content_embed_349', 'content_embed_350', 'content_embed_351', 'content_embed_352', 'content_embed_353', 'content_embed_354', 'content_embed_355', 'content_embed_356', 'content_embed_357', 'content_embed_358', 'content_embed_359', 'content_embed_360', 'content_embed_361', 'content_embed_362', 'content_embed_363', 'content_embed_364', 'content_embed_365', 'content_embed_366', 'content_embed_367', 'content_embed_368', 'content_embed_369', 'content_embed_370', 'content_embed_371', 'content_embed_372', 'content_embed_373', 'content_embed_374', 'content_embed_375', 'content_embed_376', 'content_embed_377', 'content_embed_378', 'content_embed_379', 'content_embed_380', 'content_embed_381', 'content_embed_382', 'content_embed_383', 'content_embed_384', 'content_embed_385', 'content_embed_386', 'content_embed_387', 'content_embed_388', 'content_embed_389', 'content_embed_390', 'content_embed_391', 'content_embed_392', 'content_embed_393', 'content_embed_394', 'content_embed_395', 'content_embed_396', 'content_embed_397', 'content_embed_398', 'content_embed_399', 'content_embed_400', 'content_embed_401', 'content_embed_402', 'content_embed_403', 'content_embed_404', 'content_embed_405', 'content_embed_406', 'content_embed_407', 'content_embed_408', 'content_embed_409', 'content_embed_410', 'content_embed_411', 'content_embed_412', 'content_embed_413', 'content_embed_414', 'content_embed_415', 'content_embed_416', 'content_embed_417', 'content_embed_418', 'content_embed_419', 'content_embed_420', 'content_embed_421', 'content_embed_422', 'content_embed_423', 'content_embed_424', 'content_embed_425', 'content_embed_426', 'content_embed_427', 'content_embed_428', 'content_embed_429', 'content_embed_430', 'content_embed_431', 'content_embed_432', 'content_embed_433', 'content_embed_434', 'content_embed_435', 'content_embed_436', 'content_embed_437', 'content_embed_438', 'content_embed_439', 'content_embed_440', 'content_embed_441', 'content_embed_442', 'content_embed_443', 'content_embed_444', 'content_embed_445', 'content_embed_446', 'content_embed_447', 'content_embed_448', 'content_embed_449', 'content_embed_450', 'content_embed_451', 'content_embed_452', 'content_embed_453', 'content_embed_454', 'content_embed_455', 'content_embed_456', 'content_embed_457', 'content_embed_458', 'content_embed_459', 'content_embed_460', 'content_embed_461', 'content_embed_462', 'content_embed_463', 'content_embed_464', 'content_embed_465', 'content_embed_466', 'content_embed_467', 'content_embed_468', 'content_embed_469', 'content_embed_470', 'content_embed_471', 'content_embed_472', 'content_embed_473', 'content_embed_474', 'content_embed_475', 'content_embed_476', 'content_embed_477', 'content_embed_478', 'content_embed_479', 'content_embed_480', 'content_embed_481', 'content_embed_482', 'content_embed_483', 'content_embed_484', 'content_embed_485', 'content_embed_486', 'content_embed_487', 'content_embed_488', 'content_embed_489', 'content_embed_490', 'content_embed_491', 'content_embed_492', 'content_embed_493', 'content_embed_494', 'content_embed_495', 'content_embed_496', 'content_embed_497', 'content_embed_498', 'content_embed_499', 'content_embed_500', 'content_embed_501', 'content_embed_502', 'content_embed_503', 'content_embed_504', 'content_embed_505', 'content_embed_506', 'content_embed_507', 'content_embed_508', 'content_embed_509', 'content_embed_510', 'content_embed_511', 'content_embed_512', 'content_embed_513', 'content_embed_514', 'content_embed_515', 'content_embed_516', 'content_embed_517', 'content_embed_518', 'content_embed_519', 'content_embed_520', 'content_embed_521', 'content_embed_522', 'content_embed_523', 'content_embed_524', 'content_embed_525', 'content_embed_526', 'content_embed_527', 'content_embed_528', 'content_embed_529', 'content_embed_530', 'content_embed_531', 'content_embed_532', 'content_embed_533', 'content_embed_534', 'content_embed_535', 'content_embed_536', 'content_embed_537', 'content_embed_538', 'content_embed_539', 'content_embed_540', 'content_embed_541', 'content_embed_542', 'content_embed_543', 'content_embed_544', 'content_embed_545', 'content_embed_546', 'content_embed_547', 'content_embed_548', 'content_embed_549', 'content_embed_550', 'content_embed_551', 'content_embed_552', 'content_embed_553', 'content_embed_554', 'content_embed_555', 'content_embed_556', 'content_embed_557', 'content_embed_558', 'content_embed_559', 'content_embed_560', 'content_embed_561', 'content_embed_562', 'content_embed_563', 'content_embed_564', 'content_embed_565', 'content_embed_566', 'content_embed_567', 'content_embed_568', 'content_embed_569', 'content_embed_570', 'content_embed_571', 'content_embed_572', 'content_embed_573', 'content_embed_574', 'content_embed_575', 'content_embed_576', 'content_embed_577', 'content_embed_578', 'content_embed_579', 'content_embed_580', 'content_embed_581', 'content_embed_582', 'content_embed_583', 'content_embed_584', 'content_embed_585', 'content_embed_586', 'content_embed_587', 'content_embed_588', 'content_embed_589', 'content_embed_590', 'content_embed_591', 'content_embed_592', 'content_embed_593', 'content_embed_594', 'content_embed_595', 'content_embed_596', 'content_embed_597', 'content_embed_598', 'content_embed_599', 'content_embed_600', 'content_embed_601', 'content_embed_602', 'content_embed_603', 'content_embed_604', 'content_embed_605', 'content_embed_606', 'content_embed_607', 'content_embed_608', 'content_embed_609', 'content_embed_610', 'content_embed_611', 'content_embed_612', 'content_embed_613', 'content_embed_614', 'content_embed_615', 'content_embed_616', 'content_embed_617', 'content_embed_618', 'content_embed_619', 'content_embed_620', 'content_embed_621', 'content_embed_622', 'content_embed_623', 'content_embed_624', 'content_embed_625', 'content_embed_626', 'content_embed_627', 'content_embed_628', 'content_embed_629', 'content_embed_630', 'content_embed_631', 'content_embed_632', 'content_embed_633', 'content_embed_634', 'content_embed_635', 'content_embed_636', 'content_embed_637', 'content_embed_638', 'content_embed_639', 'content_embed_640', 'content_embed_641', 'content_embed_642', 'content_embed_643', 'content_embed_644', 'content_embed_645', 'content_embed_646', 'content_embed_647', 'content_embed_648', 'content_embed_649', 'content_embed_650', 'content_embed_651', 'content_embed_652', 'content_embed_653', 'content_embed_654', 'content_embed_655', 'content_embed_656', 'content_embed_657', 'content_embed_658', 'content_embed_659', 'content_embed_660', 'content_embed_661', 'content_embed_662', 'content_embed_663', 'content_embed_664', 'content_embed_665', 'content_embed_666', 'content_embed_667', 'content_embed_668', 'content_embed_669', 'content_embed_670', 'content_embed_671', 'content_embed_672', 'content_embed_673', 'content_embed_674', 'content_embed_675', 'content_embed_676', 'content_embed_677', 'content_embed_678', 'content_embed_679', 'content_embed_680', 'content_embed_681', 'content_embed_682', 'content_embed_683', 'content_embed_684', 'content_embed_685', 'content_embed_686', 'content_embed_687', 'content_embed_688', 'content_embed_689', 'content_embed_690', 'content_embed_691', 'content_embed_692', 'content_embed_693', 'content_embed_694', 'content_embed_695', 'content_embed_696', 'content_embed_697', 'content_embed_698', 'content_embed_699', 'content_embed_700', 'content_embed_701', 'content_embed_702', 'content_embed_703', 'content_embed_704', 'content_embed_705', 'content_embed_706', 'content_embed_707', 'content_embed_708', 'content_embed_709', 'content_embed_710', 'content_embed_711', 'content_embed_712', 'content_embed_713', 'content_embed_714', 'content_embed_715', 'content_embed_716', 'content_embed_717', 'content_embed_718', 'content_embed_719', 'content_embed_720', 'content_embed_721', 'content_embed_722', 'content_embed_723', 'content_embed_724', 'content_embed_725', 'content_embed_726', 'content_embed_727', 'content_embed_728', 'content_embed_729', 'content_embed_730', 'content_embed_731', 'content_embed_732', 'content_embed_733', 'content_embed_734', 'content_embed_735', 'content_embed_736', 'content_embed_737', 'content_embed_738', 'content_embed_739', 'content_embed_740', 'content_embed_741', 'content_embed_742', 'content_embed_743', 'content_embed_744', 'content_embed_745', 'content_embed_746', 'content_embed_747', 'content_embed_748', 'content_embed_749', 'content_embed_750', 'content_embed_751', 'content_embed_752', 'content_embed_753', 'content_embed_754', 'content_embed_755', 'content_embed_756', 'content_embed_757', 'content_embed_758', 'content_embed_759', 'content_embed_760', 'content_embed_761', 'content_embed_762', 'content_embed_763', 'content_embed_764', 'content_embed_765', 'content_embed_766', 'content_embed_767', 'url_embed_0', 'url_embed_1', 'url_embed_2', 'url_embed_3', 'url_embed_4', 'url_embed_5', 'url_embed_6', 'url_embed_7', 'url_embed_8', 'url_embed_9', 'url_embed_10', 'url_embed_11', 'url_embed_12', 'url_embed_13', 'url_embed_14', 'url_embed_15', 'url_embed_16', 'url_embed_17', 'url_embed_18', 'url_embed_19', 'url_embed_20', 'url_embed_21', 'url_embed_22', 'url_embed_23', 'url_embed_24', 'url_embed_25', 'url_embed_26', 'url_embed_27', 'url_embed_28', 'url_embed_29', 'url_embed_30', 'url_embed_31', 'url_embed_32', 'url_embed_33', 'url_embed_34', 'url_embed_35', 'url_embed_36', 'url_embed_37', 'url_embed_38', 'url_embed_39', 'url_embed_40', 'url_embed_41', 'url_embed_42', 'url_embed_43', 'url_embed_44', 'url_embed_45', 'url_embed_46', 'url_embed_47', 'url_embed_48', 'url_embed_49', 'url_embed_50', 'url_embed_51', 'url_embed_52', 'url_embed_53', 'url_embed_54', 'url_embed_55', 'url_embed_56', 'url_embed_57', 'url_embed_58', 'url_embed_59', 'url_embed_60', 'url_embed_61', 'url_embed_62', 'url_embed_63', 'url_embed_64', 'url_embed_65', 'url_embed_66', 'url_embed_67', 'url_embed_68', 'url_embed_69', 'url_embed_70', 'url_embed_71', 'url_embed_72', 'url_embed_73', 'url_embed_74', 'url_embed_75', 'url_embed_76', 'url_embed_77', 'url_embed_78', 'url_embed_79', 'url_embed_80', 'url_embed_81', 'url_embed_82', 'url_embed_83', 'url_embed_84', 'url_embed_85', 'url_embed_86', 'url_embed_87', 'url_embed_88', 'url_embed_89', 'url_embed_90', 'url_embed_91', 'url_embed_92', 'url_embed_93', 'url_embed_94', 'url_embed_95', 'url_embed_96', 'url_embed_97', 'url_embed_98', 'url_embed_99', 'url_embed_100', 'url_embed_101', 'url_embed_102', 'url_embed_103', 'url_embed_104', 'url_embed_105', 'url_embed_106', 'url_embed_107', 'url_embed_108', 'url_embed_109', 'url_embed_110', 'url_embed_111', 'url_embed_112', 'url_embed_113', 'url_embed_114', 'url_embed_115', 'url_embed_116', 'url_embed_117', 'url_embed_118', 'url_embed_119', 'url_embed_120', 'url_embed_121', 'url_embed_122', 'url_embed_123', 'url_embed_124', 'url_embed_125', 'url_embed_126', 'url_embed_127', 'url_embed_128', 'url_embed_129', 'url_embed_130', 'url_embed_131', 'url_embed_132', 'url_embed_133', 'url_embed_134', 'url_embed_135', 'url_embed_136', 'url_embed_137', 'url_embed_138', 'url_embed_139', 'url_embed_140', 'url_embed_141', 'url_embed_142', 'url_embed_143', 'url_embed_144', 'url_embed_145', 'url_embed_146', 'url_embed_147', 'url_embed_148', 'url_embed_149', 'url_embed_150', 'url_embed_151', 'url_embed_152', 'url_embed_153', 'url_embed_154', 'url_embed_155', 'url_embed_156', 'url_embed_157', 'url_embed_158', 'url_embed_159', 'url_embed_160', 'url_embed_161', 'url_embed_162', 'url_embed_163', 'url_embed_164', 'url_embed_165', 'url_embed_166', 'url_embed_167', 'url_embed_168', 'url_embed_169', 'url_embed_170', 'url_embed_171', 'url_embed_172', 'url_embed_173', 'url_embed_174', 'url_embed_175', 'url_embed_176', 'url_embed_177', 'url_embed_178', 'url_embed_179', 'url_embed_180', 'url_embed_181', 'url_embed_182', 'url_embed_183', 'url_embed_184', 'url_embed_185', 'url_embed_186', 'url_embed_187', 'url_embed_188', 'url_embed_189', 'url_embed_190', 'url_embed_191', 'url_embed_192', 'url_embed_193', 'url_embed_194', 'url_embed_195', 'url_embed_196', 'url_embed_197', 'url_embed_198', 'url_embed_199', 'url_embed_200', 'url_embed_201', 'url_embed_202', 'url_embed_203', 'url_embed_204', 'url_embed_205', 'url_embed_206', 'url_embed_207', 'url_embed_208', 'url_embed_209', 'url_embed_210', 'url_embed_211', 'url_embed_212', 'url_embed_213', 'url_embed_214', 'url_embed_215', 'url_embed_216', 'url_embed_217', 'url_embed_218', 'url_embed_219', 'url_embed_220', 'url_embed_221', 'url_embed_222', 'url_embed_223', 'url_embed_224', 'url_embed_225', 'url_embed_226', 'url_embed_227', 'url_embed_228', 'url_embed_229', 'url_embed_230', 'url_embed_231', 'url_embed_232', 'url_embed_233', 'url_embed_234', 'url_embed_235', 'url_embed_236', 'url_embed_237', 'url_embed_238', 'url_embed_239', 'url_embed_240', 'url_embed_241', 'url_embed_242', 'url_embed_243', 'url_embed_244', 'url_embed_245', 'url_embed_246', 'url_embed_247', 'url_embed_248', 'url_embed_249', 'url_embed_250', 'url_embed_251', 'url_embed_252', 'url_embed_253', 'url_embed_254', 'url_embed_255', 'url_embed_256', 'url_embed_257', 'url_embed_258', 'url_embed_259', 'url_embed_260', 'url_embed_261', 'url_embed_262', 'url_embed_263', 'url_embed_264', 'url_embed_265', 'url_embed_266', 'url_embed_267', 'url_embed_268', 'url_embed_269', 'url_embed_270', 'url_embed_271', 'url_embed_272', 'url_embed_273', 'url_embed_274', 'url_embed_275', 'url_embed_276', 'url_embed_277', 'url_embed_278', 'url_embed_279', 'url_embed_280', 'url_embed_281', 'url_embed_282', 'url_embed_283', 'url_embed_284', 'url_embed_285', 'url_embed_286', 'url_embed_287', 'url_embed_288', 'url_embed_289', 'url_embed_290', 'url_embed_291', 'url_embed_292', 'url_embed_293', 'url_embed_294', 'url_embed_295', 'url_embed_296', 'url_embed_297', 'url_embed_298', 'url_embed_299', 'url_embed_300', 'url_embed_301', 'url_embed_302', 'url_embed_303', 'url_embed_304', 'url_embed_305', 'url_embed_306', 'url_embed_307', 'url_embed_308', 'url_embed_309', 'url_embed_310', 'url_embed_311', 'url_embed_312', 'url_embed_313', 'url_embed_314', 'url_embed_315', 'url_embed_316', 'url_embed_317', 'url_embed_318', 'url_embed_319', 'url_embed_320', 'url_embed_321', 'url_embed_322', 'url_embed_323', 'url_embed_324', 'url_embed_325', 'url_embed_326', 'url_embed_327', 'url_embed_328', 'url_embed_329', 'url_embed_330', 'url_embed_331', 'url_embed_332', 'url_embed_333', 'url_embed_334', 'url_embed_335', 'url_embed_336', 'url_embed_337', 'url_embed_338', 'url_embed_339', 'url_embed_340', 'url_embed_341', 'url_embed_342', 'url_embed_343', 'url_embed_344', 'url_embed_345', 'url_embed_346', 'url_embed_347', 'url_embed_348', 'url_embed_349', 'url_embed_350', 'url_embed_351', 'url_embed_352', 'url_embed_353', 'url_embed_354', 'url_embed_355', 'url_embed_356', 'url_embed_357', 'url_embed_358', 'url_embed_359', 'url_embed_360', 'url_embed_361', 'url_embed_362', 'url_embed_363', 'url_embed_364', 'url_embed_365', 'url_embed_366', 'url_embed_367', 'url_embed_368', 'url_embed_369', 'url_embed_370', 'url_embed_371', 'url_embed_372', 'url_embed_373', 'url_embed_374', 'url_embed_375', 'url_embed_376', 'url_embed_377', 'url_embed_378', 'url_embed_379', 'url_embed_380', 'url_embed_381', 'url_embed_382', 'url_embed_383', 'url_embed_384', 'url_embed_385', 'url_embed_386', 'url_embed_387', 'url_embed_388', 'url_embed_389', 'url_embed_390', 'url_embed_391', 'url_embed_392', 'url_embed_393', 'url_embed_394', 'url_embed_395', 'url_embed_396', 'url_embed_397', 'url_embed_398', 'url_embed_399', 'url_embed_400', 'url_embed_401', 'url_embed_402', 'url_embed_403', 'url_embed_404', 'url_embed_405', 'url_embed_406', 'url_embed_407', 'url_embed_408', 'url_embed_409', 'url_embed_410', 'url_embed_411', 'url_embed_412', 'url_embed_413', 'url_embed_414', 'url_embed_415', 'url_embed_416', 'url_embed_417', 'url_embed_418', 'url_embed_419', 'url_embed_420', 'url_embed_421', 'url_embed_422', 'url_embed_423', 'url_embed_424', 'url_embed_425', 'url_embed_426', 'url_embed_427', 'url_embed_428', 'url_embed_429', 'url_embed_430', 'url_embed_431', 'url_embed_432', 'url_embed_433', 'url_embed_434', 'url_embed_435', 'url_embed_436', 'url_embed_437', 'url_embed_438', 'url_embed_439', 'url_embed_440', 'url_embed_441', 'url_embed_442', 'url_embed_443', 'url_embed_444', 'url_embed_445', 'url_embed_446', 'url_embed_447', 'url_embed_448', 'url_embed_449', 'url_embed_450', 'url_embed_451', 'url_embed_452', 'url_embed_453', 'url_embed_454', 'url_embed_455', 'url_embed_456', 'url_embed_457', 'url_embed_458', 'url_embed_459', 'url_embed_460', 'url_embed_461', 'url_embed_462', 'url_embed_463', 'url_embed_464', 'url_embed_465', 'url_embed_466', 'url_embed_467', 'url_embed_468', 'url_embed_469', 'url_embed_470', 'url_embed_471', 'url_embed_472', 'url_embed_473', 'url_embed_474', 'url_embed_475', 'url_embed_476', 'url_embed_477', 'url_embed_478', 'url_embed_479', 'url_embed_480', 'url_embed_481', 'url_embed_482', 'url_embed_483', 'url_embed_484', 'url_embed_485', 'url_embed_486', 'url_embed_487', 'url_embed_488', 'url_embed_489', 'url_embed_490', 'url_embed_491', 'url_embed_492', 'url_embed_493', 'url_embed_494', 'url_embed_495', 'url_embed_496', 'url_embed_497', 'url_embed_498', 'url_embed_499', 'url_embed_500', 'url_embed_501', 'url_embed_502', 'url_embed_503', 'url_embed_504', 'url_embed_505', 'url_embed_506', 'url_embed_507', 'url_embed_508', 'url_embed_509', 'url_embed_510', 'url_embed_511', 'url_embed_512', 'url_embed_513', 'url_embed_514', 'url_embed_515', 'url_embed_516', 'url_embed_517', 'url_embed_518', 'url_embed_519', 'url_embed_520', 'url_embed_521', 'url_embed_522', 'url_embed_523', 'url_embed_524', 'url_embed_525', 'url_embed_526', 'url_embed_527', 'url_embed_528', 'url_embed_529', 'url_embed_530', 'url_embed_531', 'url_embed_532', 'url_embed_533', 'url_embed_534', 'url_embed_535', 'url_embed_536', 'url_embed_537', 'url_embed_538', 'url_embed_539', 'url_embed_540', 'url_embed_541', 'url_embed_542', 'url_embed_543', 'url_embed_544', 'url_embed_545', 'url_embed_546', 'url_embed_547', 'url_embed_548', 'url_embed_549', 'url_embed_550', 'url_embed_551', 'url_embed_552', 'url_embed_553', 'url_embed_554', 'url_embed_555', 'url_embed_556', 'url_embed_557', 'url_embed_558', 'url_embed_559', 'url_embed_560', 'url_embed_561', 'url_embed_562', 'url_embed_563', 'url_embed_564', 'url_embed_565', 'url_embed_566', 'url_embed_567', 'url_embed_568', 'url_embed_569', 'url_embed_570', 'url_embed_571', 'url_embed_572', 'url_embed_573', 'url_embed_574', 'url_embed_575', 'url_embed_576', 'url_embed_577', 'url_embed_578', 'url_embed_579', 'url_embed_580', 'url_embed_581', 'url_embed_582', 'url_embed_583', 'url_embed_584', 'url_embed_585', 'url_embed_586', 'url_embed_587', 'url_embed_588', 'url_embed_589', 'url_embed_590', 'url_embed_591', 'url_embed_592', 'url_embed_593', 'url_embed_594', 'url_embed_595', 'url_embed_596', 'url_embed_597', 'url_embed_598', 'url_embed_599', 'url_embed_600', 'url_embed_601', 'url_embed_602', 'url_embed_603', 'url_embed_604', 'url_embed_605', 'url_embed_606', 'url_embed_607', 'url_embed_608', 'url_embed_609', 'url_embed_610', 'url_embed_611', 'url_embed_612', 'url_embed_613', 'url_embed_614', 'url_embed_615', 'url_embed_616', 'url_embed_617', 'url_embed_618', 'url_embed_619', 'url_embed_620', 'url_embed_621', 'url_embed_622', 'url_embed_623', 'url_embed_624', 'url_embed_625', 'url_embed_626', 'url_embed_627', 'url_embed_628', 'url_embed_629', 'url_embed_630', 'url_embed_631', 'url_embed_632', 'url_embed_633', 'url_embed_634', 'url_embed_635', 'url_embed_636', 'url_embed_637', 'url_embed_638', 'url_embed_639', 'url_embed_640', 'url_embed_641', 'url_embed_642', 'url_embed_643', 'url_embed_644', 'url_embed_645', 'url_embed_646', 'url_embed_647', 'url_embed_648', 'url_embed_649', 'url_embed_650', 'url_embed_651', 'url_embed_652', 'url_embed_653', 'url_embed_654', 'url_embed_655', 'url_embed_656', 'url_embed_657', 'url_embed_658', 'url_embed_659', 'url_embed_660', 'url_embed_661', 'url_embed_662', 'url_embed_663', 'url_embed_664', 'url_embed_665', 'url_embed_666', 'url_embed_667', 'url_embed_668', 'url_embed_669', 'url_embed_670', 'url_embed_671', 'url_embed_672', 'url_embed_673', 'url_embed_674', 'url_embed_675', 'url_embed_676', 'url_embed_677', 'url_embed_678', 'url_embed_679', 'url_embed_680', 'url_embed_681', 'url_embed_682', 'url_embed_683', 'url_embed_684', 'url_embed_685', 'url_embed_686', 'url_embed_687', 'url_embed_688', 'url_embed_689', 'url_embed_690', 'url_embed_691', 'url_embed_692', 'url_embed_693', 'url_embed_694', 'url_embed_695', 'url_embed_696', 'url_embed_697', 'url_embed_698', 'url_embed_699', 'url_embed_700', 'url_embed_701', 'url_embed_702', 'url_embed_703', 'url_embed_704', 'url_embed_705', 'url_embed_706', 'url_embed_707', 'url_embed_708', 'url_embed_709', 'url_embed_710', 'url_embed_711', 'url_embed_712', 'url_embed_713', 'url_embed_714', 'url_embed_715', 'url_embed_716', 'url_embed_717', 'url_embed_718', 'url_embed_719', 'url_embed_720', 'url_embed_721', 'url_embed_722', 'url_embed_723', 'url_embed_724', 'url_embed_725', 'url_embed_726', 'url_embed_727', 'url_embed_728', 'url_embed_729', 'url_embed_730', 'url_embed_731', 'url_embed_732', 'url_embed_733', 'url_embed_734', 'url_embed_735', 'url_embed_736', 'url_embed_737', 'url_embed_738', 'url_embed_739', 'url_embed_740', 'url_embed_741', 'url_embed_742', 'url_embed_743', 'url_embed_744', 'url_embed_745', 'url_embed_746', 'url_embed_747', 'url_embed_748', 'url_embed_749', 'url_embed_750', 'url_embed_751', 'url_embed_752', 'url_embed_753', 'url_embed_754', 'url_embed_755', 'url_embed_756', 'url_embed_757', 'url_embed_758', 'url_embed_759', 'url_embed_760', 'url_embed_761', 'url_embed_762', 'url_embed_763', 'url_embed_764', 'url_embed_765', 'url_embed_766', 'url_embed_767']\n",
      "Final preprocessed_X shape: (916, 1540)\n",
      "Feature combination complete.\n",
      "Preprocessed features shape: (916, 1540)\n",
      "     length  Method_GET  Method_POST  Method_PUT  content_embed_0  \\\n",
      "0 -0.428092         1.0          0.0         0.0        -0.028476   \n",
      "1 -0.428092         1.0          0.0         0.0        -0.028476   \n",
      "2 -0.428092         1.0          0.0         0.0        -0.028476   \n",
      "3 -0.428092         1.0          0.0         0.0        -0.028476   \n",
      "4 -0.428092         1.0          0.0         0.0        -0.028476   \n",
      "\n",
      "   content_embed_1  content_embed_2  content_embed_3  content_embed_4  \\\n",
      "0         0.098757         0.020165        -0.138052         0.102844   \n",
      "1         0.098757         0.020165        -0.138052         0.102844   \n",
      "2         0.098757         0.020165        -0.138052         0.102844   \n",
      "3         0.098757         0.020165        -0.138052         0.102844   \n",
      "4         0.098757         0.020165        -0.138052         0.102844   \n",
      "\n",
      "   content_embed_5  ...  url_embed_758  url_embed_759  url_embed_760  \\\n",
      "0        -0.104355  ...       0.087616       0.057487      -0.073684   \n",
      "1        -0.104355  ...       0.075865       0.050524      -0.082399   \n",
      "2        -0.104355  ...       0.066620       0.014906      -0.060394   \n",
      "3        -0.104355  ...       0.056332       0.042746      -0.047976   \n",
      "4        -0.104355  ...       0.072018       0.044067      -0.050156   \n",
      "\n",
      "   url_embed_761  url_embed_762  url_embed_763  url_embed_764  url_embed_765  \\\n",
      "0      -0.074092       0.045679       0.102323       0.098967      -0.106962   \n",
      "1      -0.050382       0.020913       0.083972       0.071844      -0.091895   \n",
      "2      -0.043616       0.046907       0.043836       0.055787      -0.092901   \n",
      "3      -0.057382       0.052227       0.083219       0.074983      -0.105109   \n",
      "4      -0.050441       0.044164       0.084519       0.076489      -0.083120   \n",
      "\n",
      "   url_embed_766  url_embed_767  \n",
      "0      -0.040197       0.035822  \n",
      "1      -0.044915       0.024573  \n",
      "2      -0.024972       0.018708  \n",
      "3      -0.041199      -0.009959  \n",
      "4      -0.035258      -0.010277  \n",
      "\n",
      "[5 rows x 1540 columns]\n",
      "Making predictions with the MLP model...\n",
      "Predictions complete.\n",
      "\n",
      "--- Prediction Process Finished ---\n",
      "Prediction counts:\n",
      "Predicted_Label\n",
      "1    899\n",
      "0     17\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Predictions complete. Resulting DataFrame head:\n",
      "    Method  length                                            content URL  \\\n",
      "896   POST      44       p=%27%3BWAITFOR%20DELAY%20%270%3A0%3A30%27--   /   \n",
      "897   POST      49  p=%22%29%29%3Bwaitfor%20delay%20%270%3A0%3A5%27--   /   \n",
      "898   POST      46     p=%22%29%3Bwaitfor%20delay%20%270%3A0%3A5%27--   /   \n",
      "899   POST      43        p=%22%3Bwaitfor%20delay%20%270%3A0%3A5%27--   /   \n",
      "900   POST      49  p=%27%29%29%3Bwaitfor%20delay%20%270%3A0%3A5%27--   /   \n",
      "901   POST      46     p=%27%29%3Bwaitfor%20delay%20%270%3A0%3A5%27--   /   \n",
      "902   POST      43        p=%27%3Bwaitfor%20delay%20%270%3A0%3A5%27--   /   \n",
      "903   POST      46     p=%29%29%3Bwaitfor%20delay%20%270%3A0%3A5%27--   /   \n",
      "904   POST      43        p=%29%3Bwaitfor%20delay%20%270%3A0%3A5%27--   /   \n",
      "905   POST      40           p=%3Bwaitfor%20delay%20%270%3A0%3A5%27--   /   \n",
      "906   POST      32                   p=%20WHERE%201%3D1%20AND%201%3D0   /   \n",
      "907   POST      35                p=%20WHERE%201%3D1%20AND%201%3D0%23   /   \n",
      "908   POST      34                 p=%20WHERE%201%3D1%20AND%201%3D0--   /   \n",
      "909   POST      32                   p=%20WHERE%201%3D1%20AND%201%3D1   /   \n",
      "910   POST      35                p=%20WHERE%201%3D1%20AND%201%3D1%23   /   \n",
      "911   POST      34                 p=%20WHERE%201%3D1%20AND%201%3D1--   /   \n",
      "912   POST      38             p=%27%20WHERE%201%3D1%20AND%201%3D1%23   /   \n",
      "913   POST     140  p=%27%20WHERE%20SUBSTRING%28%28select%20column...   /   \n",
      "914   POST      41          p=x%27%20or%201%3D1%20or%20%27x%27%3D%27y   /   \n",
      "915   POST      41          p=x%27%20OR%20full_name%20LIKE%20%27%Bob%   /   \n",
      "\n",
      "     Predicted_Probability  Predicted_Label  \n",
      "896                    1.0                1  \n",
      "897                    1.0                1  \n",
      "898                    1.0                1  \n",
      "899                    1.0                1  \n",
      "900                    1.0                1  \n",
      "901                    1.0                1  \n",
      "902                    1.0                1  \n",
      "903                    1.0                1  \n",
      "904                    1.0                1  \n",
      "905                    1.0                1  \n",
      "906                    1.0                1  \n",
      "907                    1.0                1  \n",
      "908                    1.0                1  \n",
      "909                    1.0                1  \n",
      "910                    1.0                1  \n",
      "911                    1.0                1  \n",
      "912                    1.0                1  \n",
      "913                    1.0                1  \n",
      "914                    1.0                1  \n",
      "915                    1.0                1  \n",
      "\n",
      "Predictions saved to: predictions_output.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Example Usage of the Prediction Function\n",
    "if __name__ == '__main__':\n",
    "    # --- Specify the path to your actual inference CSV file ---\n",
    "    # IMPORTANT: Replace 'path/to/your/actual_inference_data.csv' with the real path\n",
    "    # Example: 'data/unseen_network_logs.csv'\n",
    "    actual_inference_csv_path = r\"D:\\Internship ka kaam\\data.csv\\poroject\\Horizon_log\\abc.csv\"\n",
    "\n",
    "    # Check if the specified file exists before proceeding\n",
    "    if not os.path.exists(actual_inference_csv_path):\n",
    "        print(f\"Error: The specified inference CSV file does not exist at '{actual_inference_csv_path}'\")\n",
    "        print(\"Please update 'actual_inference_csv_path' with the correct path to your data.\")\n",
    "    else:\n",
    "        # --- Run Prediction ---\n",
    "        predictions_df = predict_network_payload(actual_inference_csv_path)\n",
    "\n",
    "        if predictions_df is not None:\n",
    "            print(\"\\nPredictions complete. Resulting DataFrame head:\")\n",
    "            # Print more rows to get a better overview of predictions\n",
    "            print(predictions_df.tail(20)) # Display 20 rows\n",
    "            \n",
    "            # Optional: Save the predictions to a new CSV file\n",
    "            output_csv_path = 'predictions_output.csv'\n",
    "            predictions_df.to_csv(output_csv_path, index=False)\n",
    "            print(f\"\\nPredictions saved to: {output_csv_path}\")\n",
    "\n",
    "        else:\n",
    "            print(\"\\nPrediction failed. Check error messages above.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
